{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于CIRAR-10的数据分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 项目使用的数据集是 CIFAR-10 数据集，该数据集有 50000 张图片，每张图片均为分辨率为 32*32 的彩色图片，分为3个信道。\n",
    "- 分类任务需要分成青蛙、卡车、飞机等 10 个类别。我们的目标是基本正确的识别这十类图片。\n",
    "- 为了训练该网络，首先将数据分为训练集、验证集和测试集 3 个数据集。训练集样本个数为 45000，验证集样本个数为 5000，测试集样本个数为 10000。\n",
    "- 我们设计一种卷积神经网络用于处理图像分类任务，并通过一步步改进，结合多种模型，把预测正确率从初始的85%提高到92%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理：我们使用的数据预处理方法，称为数据增强（data augmentation）技术。使用数据增强技术，主要在训练数据上增加微小的扰动或者变化，一方面可以增加训练数据，从而提升模型的性能，另一方面可以增加噪声数据，从而增强模型的鲁棒性。\n",
    "- 卷积和池化：对数据预处理后，得到的模型输入数据是是一个 4 维 tensor，尺寸为 (128, 32, 32, 3)，分别表示一批图片的个数 128（batch_size）、图片的宽和高的像素点个数都是32、信道个数为3。之后使用多个卷积神经网络层进行图像的特征提取。\n",
    "- 模型改进：在卷积层处理中，加入了权重衰减（weight decay）、批正则化（batch normalization）方法，提高预测正确率。\n",
    "- 调整参数：修改学习率，优化参数，进一步提高预测正确率。\n",
    "- 可视化：调用matplotlib库，实现对学习率，loss值，预测结果的图形化输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **流程图：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart0](images/flowchart0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart1](images/flowchart1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart2](images/flowchart2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart1_1](images/flowchart1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart2_1](images/flowchart2_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型参数是模型内部的配置变量，可以用数据估计模型参数的值；模型超参数是模型外部的配置，必须手动设置参数的值。\n",
    "- 此函数中，输入的三个参数分别的含义如下：\n",
    "    - n_channel=3：信道个数为３\n",
    "    - n_classes=10：分类的类别共有１０个\n",
    "    - image_size=24：图片的大小\n",
    "    - 对self.images、self.labels、self.keep_prob用了占位符函数tf.placeholder()进行初始化赋值。\n",
    "    - 对self.global_step使用了tf.Variable()函数进行初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, n_channel=3, n_classes=10, image_size=24):\n",
    "        # 输入变量\n",
    "        self.images = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, image_size, image_size, n_channel], name='images')\n",
    "        self.labels = tf.placeholder(\n",
    "            dtype=tf.int64, shape=[None], name='labels')\n",
    "        self.keep_prob = tf.placeholder(\n",
    "            dtype=tf.float32, name='keep_prob')\n",
    "        self.global_step = tf.Variable( \n",
    "            0, dtype=tf.int32, name='global_step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积网络与池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图 1、只含卷积和池化的 loss 收敛曲线图和验证集准确率图](images/cifar10-v1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        图 1、只含卷积和池化的 loss 收敛曲线图和验证集准确率图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强\n",
    "- 数据增强：主要是在训练数据上增加微小的扰动或者变化，一方面可以增加训练数据，从而提升模型的泛化能力，另一方面可以增加噪声数据，从而增强模型的健壮性。\n",
    "\n",
    "- 主要的数据增强方法有：翻转变换 flip、随机修剪（random crop）、色彩抖动（color jittering）、平移变换（shift）、尺度变换（scale）、对比度变换（contrast）、噪声扰动（noise）、旋转变换/反射变换 （rotation/reflection）等\n",
    "    - 图像切割 (_image_crop)：生成比图像尺寸小一些的矩形框，对图像进行随机的切割，最终以矩形框内的图像作为训练数据。\n",
    "    - 图像翻转 (_image_flip)：随机对图像进行左右翻转。\n",
    "    - 图像白化：对图像进行白化操作，即将图像本身归一化成 Gaussian(0,1) 分布。\n",
    "    - 图像噪声：防止过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(self, images, mode='train', flip=False,\n",
    "                      crop=False, crop_shape=(24,24,3), whiten=False,\n",
    "                      noise=False, noise_mean=0, noise_std=0.01):\n",
    "    # 图像切割\n",
    "    if crop:\n",
    "        if mode == 'train':           \n",
    "            images = self._image_crop(images, shape=crop_shape)\n",
    "        elif mode == 'test':\n",
    "            images = self._image_crop_test(images, shape=crop_shape)\n",
    "    # 图像翻转\n",
    "    if flip:\n",
    "        images = self._image_flip(images)\n",
    "    # 图像白化\n",
    "    if whiten:\n",
    "        images = self._image_whitening(images)\n",
    "    # 图像噪声\n",
    "    if noise:\n",
    "        images = self._image_noise(images, mean=noise_mean, std=noise_std)\n",
    "            \n",
    "    return images                                                              \n",
    "def _image_crop(self, images, shape):\n",
    "    # 图像切割\n",
    "    new_images = []\n",
    "    for i in range(images.shape[0]):\n",
    "        old_image = images[i,:,:,:]\n",
    "        # 返回左闭右开区间[0,old_image.shape[0] - shape[0] + 1）上离散均匀分布的整数值\n",
    "        left = numpy.random.randint(old_image.shape[0] - shape[0] + 1)\n",
    "        top = numpy.random.randint(old_image.shape[1] - shape[1] + 1)\n",
    "        new_image = old_image[left: left+shape[0], top: top+shape[1], :]\n",
    "        new_images.append(new_image)\n",
    "        \n",
    "    return numpy.array(new_images)\n",
    "        \n",
    "    \n",
    "def _image_crop_test(self, images, shape):\n",
    "    # 图像切割\n",
    "    new_images = []\n",
    "    for i in range(images.shape[0]):        \n",
    "        old_image = images[i,:,:,:]\n",
    "        left = int((old_image.shape[0] - shape[0]) / 2)\n",
    "        top = int((old_image.shape[1] - shape[1]) / 2)\n",
    "        new_image = old_image[left: left+shape[0], top: top+shape[1], :]\n",
    "        new_images.append(new_image)\n",
    "        \n",
    "    return numpy.array(new_images)\n",
    "        \n",
    "    \n",
    "def _image_flip(self, images):\n",
    "    # 图像翻转\n",
    "    for i in range(images.shape[0]):\n",
    "        old_image = images[i,:,:,:]\n",
    "        # numpy.random.random()随机生成在[0.0,1.0]中的浮点数\n",
    "        if numpy.random.random() < 0.5:\n",
    "            # cv2.flip(old_image, 1)对图像进行水平翻转\n",
    "            new_image = cv2.flip(old_image, 1)\n",
    "        else:\n",
    "            new_image = old_image\n",
    "        images[i,:,:,:] = new_image\n",
    "        \n",
    "    return images\n",
    "    \n",
    "def _image_whitening(self, images):\n",
    "    # 图像白化，即归一化处理\n",
    "    for i in range(images.shape[0]):\n",
    "        old_image = images[i,:,:,:]\n",
    "        # numpy.mean()求均值；　numpy.std()求标准差；\n",
    "        new_image = (old_image - numpy.mean(old_image)) / numpy.std(old_image)\n",
    "        images[i,:,:,:] = new_image\n",
    "        \n",
    "    return images\n",
    "    \n",
    "def _image_noise(self, images, mean=0, std=0.01):\n",
    "    # 图像噪声\n",
    "    for i in range(images.shape[0]):\n",
    "        old_image = images[i,:,:,:]\n",
    "        new_image = old_image\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                for k in range(image.shape[2]):\n",
    "                    # 生成随机数，将其加到像素值上，这里使用的是高斯噪声\n",
    "                    new_image[i, j, k] += random.gauss(mean, std)\n",
    "        images[i,:,:,:] = new_image\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图2、加入数据增强步骤之后的loss 收敛曲线图和验证集准确率图](images/cifar10-v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                       图2、加入数据增强步骤之后的收敛曲线图和验证集准确率图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型改进"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 权重衰减\n",
    "\n",
    "- 对于目标函数加入正则化项，限制权重参数的个数，这是一种防止过拟合的方法。用训练集对模型进行训练时，如果不对参数加以限制，虽然对于训练集来说，模型的识别准确率会越来越高，但换成其他数据集就识别率就会下降，这种情况就叫过拟合。或者说是为了提高泛化能力。\n",
    "- 上述事例中，先将weight（权重）传入损失函数中，然后与初始的weight decay做乘法作为新的权重系数，接着将其与'losses'字符串一起放入集合，变成list。正则项一般指模型的复杂度，weight decay可以调节模型复杂度对损失函数的影响，weight decay越大，复杂模型损失函数的值就会越大。\n",
    "- 调用实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weight_decay:\n",
    "    weight_decay = tf.multiply(tf.nn.l2_loss(self.weight), self.weight_decay)\n",
    "    tf.add_to_collection('losses', weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropout\n",
    "\n",
    "- 在每次训练的时候，让某些的特征检测器停过工作，即让神经元以一定的概率不被激活，这样可以防止过拟合，提高泛化能力。目的和权重衰减一模一样，只是方法不同，权重衰减是通过限制参数，而dropout是限制每次激活的神经元数量。\n",
    "- self.hidden为训练或者测试数据，keep_porb是倍率，停止的神经元数据会变为0，而其他的则变成原来的1/keep_prob倍。每次停止的神经元一般通过随机算法选出来，从动机论的角度来讲，随机搭配工作的神经元，能够减少相互之间的依赖性，泛化能力相应就会提高了。\n",
    "\n",
    "- 调用实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.dropout:\n",
    "    self.hidden = tf.nn.dropout(self.hidden, keep_prob=self.keep_prob)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 批正则化\n",
    "\n",
    "- batch normalization对神经网络的每一层的输入数据都进行正则化处理，这样有利于让数据的分布更加均匀，不会出现所有数据都会导致神经元的激活，或者所有数据都不会导致神经元的激活，这是一种数据标准化方法，能够提升模型的拟合能力。\n",
    "- 首先计算统计矩，mean为一阶矩，也就是均值，variance为二阶中心矩即方差，axes[0]表示按列计算，随后将这两个数据作为参数调用batch normalization函数，返回为输入。批正则化不仅能提升模型的拟合能力，而且加大探索步长，加快收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.batch_normal:\n",
    "    mean, variance = tf.nn.moments(intermediate, axes=[0])\n",
    "    self.hidden = tf.nn.batch_normalization(\n",
    "        intermediate, mean, variance, self.bias, self.gamma, self.epsilon)\n",
    "else:\n",
    "    self.hidden = intermediate + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图3、加入模型改进之后的收敛曲线和验证集准确率对比图](images/cifar10-v6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                 图3、加入模型改进之后的收敛曲线和验证集准确率对比图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "- 优化器：具体作用是用来随着epoch的增加，使得学习率不断地进行变化，从而提升模型性能\n",
    "- 上述代码主要实现了变化学习率的技术，在前50000个batch使用0.01的学习率，之后50000~100000个batch使用0.001的学习率，之后的学习率降到0.0001\n",
    "- 为了进行实验对比\n",
    "    - 实验 1：只使用 0.01 的学习率训练。\n",
    "    - 实验 2：前 10000 轮使用 0.01 的学习率，10000 轮之后学习率降到 0.001。\n",
    "    - 实验 3：前 10000 轮使用 0.01 的学习率，10000~20000 轮使用 0.001 的学习率，20000 轮之后学习率降到 0.0005。\n",
    "   观察到 loss 变化曲线和验证集准确率变化曲线对比如图4。\n",
    "\n",
    "可以观察到，当 10000 轮时，学习率从 0.01 降到 0.001 时，目标函数值有明显的下降，验证集准确率有明显的提升，而当 20000 轮时，学习率从 0.001 降到 0.0005 时，目标函数值没有明显的下降，但是验证集准确率有一定的提升，而对于测试集，准确率也提升至 86.24%。这说明，学习率的变化确实能够提升模型的拟合能力，从而提升准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.cond(tf.less(self.global_step, 50000),\n",
    "             lambda: tf.constant(0.01),\n",
    "             lambda: tf.cond(tf.less(self.global_step, 100000),\n",
    "                             lambda: tf.constant(0.001),\n",
    "                             lambda: tf.constant(0.0001)))\n",
    "self.optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(\n",
    "            self.avg_loss, global_step=self.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图4、使用不同学习率的收敛曲线和验证集准确率对比图](images/cifar10-v11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                 图4、使用不同学习率的收敛曲线和验证集准确率对比图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 残差网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差网络技术，解决由于网络层数加深而引起的梯度消失问题。这里我们先介绍一下梯度消失问题:\n",
    "- **梯度消失：**在使用深度神经网络时，优化神经网络的方法都是基于反向传播的思想，即根据损失函数计算的误差通过梯度反向传播的方式，指导深度网络权值的更新优化。首先，深层网络由许多非线性层堆叠而来，如果使用了不合适的loss反向传播算法，随着层数增多，求出的梯度更新信息将会以指数形式衰减，即发生了梯度消失。\n",
    "- **残差网络：**可以分为快捷连接和恒等映射两部分。快捷连接使得残差变得可能，而恒等映射使得网络变深，而恒等映射主要有两个：快捷连接为恒等映射和相加后的激活函数。\n",
    "    - 残差单元：使用的是批正则化（batch normalization）方法，主要思路是对每次前向传播的过程中对数据进行正态分布的归一化调整\n",
    "    - 快捷连接：包含卷积和 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(self, images):  # 前向传播\n",
    "        n_layers = int((self.n_layers - 2) / 6)\n",
    "        # 网络结构\n",
    "        # 第一层卷积\n",
    "        conv_layer0_list = []\n",
    "        conv_layer0_list.append(\n",
    "            ConvLayer(\n",
    "                input_shape=(None, self.image_size,\n",
    "                             self.image_size, self.n_channel),\n",
    "                n_size=3, n_filter=64, stride=1, activation='relu',\n",
    "                batch_normal=True, weight_decay=1e-4, name='conv0'))\n",
    "\n",
    "        conv_layer1_list = []\n",
    "        for i in range(1, n_layers+1):\n",
    "            conv_layer1_list.append(\n",
    "                ConvLayer(\n",
    "                    input_shape=(None, self.image_size, self.image_size, 64),\n",
    "                    n_size=3, n_filter=64, stride=1, activation='relu',\n",
    "                    batch_normal=True, weight_decay=1e-4, name='conv1_%d' % (2*i-1)))\n",
    "            conv_layer1_list.append(\n",
    "                ConvLayer(\n",
    "                    input_shape=(None, self.image_size, self.image_size, 64),\n",
    "                    n_size=3, n_filter=64, stride=1, activation='none',\n",
    "                    batch_normal=True, weight_decay=1e-4, name='conv1_%d' % (2*i)))\n",
    "        # 第二层卷积\n",
    "        conv_layer2_list = []\n",
    "        conv_layer2_list.append(\n",
    "            ConvLayer(\n",
    "                input_shape=(None, self.image_size, self.image_size, 64),\n",
    "                n_size=3, n_filter=128, stride=2, activation='relu',\n",
    "                batch_normal=True, weight_decay=1e-4, name='conv2_1'))\n",
    "        conv_layer2_list.append(\n",
    "            ConvLayer(\n",
    "                input_shape=(None, int(self.image_size)/2,\n",
    "                             int(self.image_size)/2, 128),\n",
    "                n_size=3, n_filter=128, stride=1, activation='none',\n",
    "                batch_normal=True, weight_decay=1e-4, name='conv2_2'))\n",
    "        for i in range(2, n_layers+1):\n",
    "            conv_layer2_list.append(\n",
    "                ConvLayer(\n",
    "                    input_shape=(None, int(self.image_size/2),\n",
    "                                 int(self.image_size/2), 128),\n",
    "                    n_size=3, n_filter=128, stride=1, activation='relu',\n",
    "                    batch_normal=True, weight_decay=1e-4, name='conv2_%d' % (2*i-1)))\n",
    "            conv_layer2_list.append(\n",
    "                ConvLayer(\n",
    "                    input_shape=(None, int(self.image_size/2),\n",
    "                                 int(self.image_size/2), 128),\n",
    "                    n_size=3, n_filter=128, stride=1, activation='none',\n",
    "                    batch_normal=True, weight_decay=1e-4, name='conv2_%d' % (2*i)))\n",
    "        # 第三层卷积\n",
    "        conv_layer3_list = []\n",
    "        conv_layer3_list.append(\n",
    "            ConvLayer(\n",
    "                input_shape=(None, int(self.image_size/2),\n",
    "                             int(self.image_size/2), 128),\n",
    "                n_size=3, n_filter=256, stride=2, activation='relu',\n",
    "                batch_normal=True, weight_decay=1e-4, name='conv3_1'))\n",
    "        conv_layer3_list.append(\n",
    "            ConvLayer(\n",
    "                input_shape=(None, int(self.image_size/4),\n",
    "                             int(self.image_size/4), 256),\n",
    "                n_size=3, n_filter=256, stride=1, activation='relu',\n",
    "                batch_normal=True, weight_decay=1e-4, name='conv3_2'))\n",
    "        for i in range(2, n_layers+1):\n",
    "            conv_layer3_list.append(\n",
    "                ConvLayer(\n",
    "                    input_shape=(None, int(self.image_size/4),\n",
    "                                 int(self.image_size/4), 256),\n",
    "                    n_size=3, n_filter=256, stride=1, activation='relu',\n",
    "                    batch_normal=True, weight_decay=1e-4, name='conv3_%d' % (2*i-1)))\n",
    "            conv_layer3_list.append(\n",
    "                ConvLayer(\n",
    "                    input_shape=(None, int(self.image_size/4),\n",
    "                                 int(self.image_size/4), 256),\n",
    "                    n_size=3, n_filter=256, stride=1, activation='none',\n",
    "                    batch_normal=True, weight_decay=1e-4, name='conv3_%d' % (2*i)))\n",
    "        # 密集层\n",
    "        dense_layer1 = DenseLayer(\n",
    "            input_shape=(None, 256),\n",
    "            hidden_dim=self.n_classes,\n",
    "            activation='none', dropout=False, keep_prob=None,\n",
    "            batch_normal=False, weight_decay=1e-4, name='dense1')\n",
    "\n",
    "        # 数据流\n",
    "        hidden_conv = conv_layer0_list[0].get_output(input=images)\n",
    "\n",
    "        for i in range(0, n_layers):\n",
    "            hidden_conv1 = conv_layer1_list[2*i].get_output(input=hidden_conv)\n",
    "            hidden_conv2 = conv_layer1_list[2 *\n",
    "                                            i+1].get_output(input=hidden_conv1)\n",
    "            hidden_conv = tf.nn.relu(hidden_conv + hidden_conv2)\n",
    "\n",
    "        hidden_conv1 = conv_layer2_list[0].get_output(input=hidden_conv)\n",
    "        hidden_conv2 = conv_layer2_list[1].get_output(input=hidden_conv1)\n",
    "        hidden_pool = tf.nn.max_pool(\n",
    "            hidden_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        hidden_pad = tf.pad(hidden_pool, [[0, 0], [0, 0], [0, 0], [32, 32]])\n",
    "        hidden_conv = tf.nn.relu(hidden_pad + hidden_conv2)\n",
    "        for i in range(1, n_layers):\n",
    "            hidden_conv1 = conv_layer2_list[2*i].get_output(input=hidden_conv)\n",
    "            hidden_conv2 = conv_layer2_list[2 *\n",
    "                                            i+1].get_output(input=hidden_conv1)\n",
    "            hidden_conv = tf.nn.relu(hidden_conv + hidden_conv2)\n",
    "\n",
    "        hidden_conv1 = conv_layer3_list[0].get_output(input=hidden_conv)\n",
    "        hidden_conv2 = conv_layer3_list[1].get_output(input=hidden_conv1)\n",
    "        hidden_pool = tf.nn.max_pool(\n",
    "            hidden_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        hidden_pad = tf.pad(hidden_pool, [[0, 0], [0, 0], [0, 0], [64, 64]])\n",
    "        hidden_conv = tf.nn.relu(hidden_pad + hidden_conv2)\n",
    "        for i in range(1, n_layers):\n",
    "            hidden_conv1 = conv_layer3_list[2*i].get_output(input=hidden_conv)\n",
    "            hidden_conv2 = conv_layer3_list[2 *\n",
    "                                            i+1].get_output(input=hidden_conv1)\n",
    "            hidden_conv = tf.nn.relu(hidden_conv + hidden_conv2)\n",
    "\n",
    "        # global average pooling\n",
    "        input_dense1 = tf.reduce_mean(hidden_conv, reduction_indices=[1, 2])\n",
    "        logits = dense_layer1.get_output(input=input_dense1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图5、使用残差网络的收敛曲线和验证集准确率对比图](images/cifar10-v20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                             图5、使用残差网络的收敛曲线和验证集准确率对比图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用matplotlib实现收敛曲线和验证集准确率对比图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对训练输出按行进行正则匹配，匹配出每一行的loss值和验证集准确率\n",
    "- 根据匹配出的loss值和所有的准确率绘图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分训练输出示例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch{0}, iter[352], train loss: 204.713004, valid precision: 0.578600, valid loss: 154.874994\n",
    "epoch{1}, iter[704], train loss: 146.363185, valid precision: 0.663400, valid loss: 123.470159\n",
    "epoch{2}, iter[1056], train loss: 120.594962, valid precision: 0.727800, valid loss: 101.386199\n",
    "epoch{3}, iter[1408], train loss: 106.502992, valid precision: 0.761400, valid loss: 88.899106\n",
    "epoch{4}, iter[1760], train loss: 97.166766, valid precision: 0.779000, valid loss: 83.838187\n",
    "epoch{5}, iter[2112], train loss: 90.350634, valid precision: 0.790400, valid loss: 78.249836\n",
    "epoch{6}, iter[2464], train loss: 85.122164, valid precision: 0.784600, valid loss: 79.144579\n",
    "epoch{7}, iter[2816], train loss: 81.727279, valid precision: 0.794600, valid loss: 77.166487\n",
    "epoch{8}, iter[3168], train loss: 78.872099, valid precision: 0.806400, valid loss: 72.316427\n",
    "epoch{9}, iter[3520], train loss: 75.402065, valid precision: 0.811200, valid loss: 71.503949\n",
    "epoch{10}, iter[3872], train loss: 73.391846, valid precision: 0.820600, valid loss: 69.149406\n",
    "epoch{11}, iter[4224], train loss: 71.720510, valid precision: 0.817200, valid loss: 68.170180\n",
    "epoch{12}, iter[4576], train loss: 69.427145, valid precision: 0.822200, valid loss: 68.986446\n",
    "epoch{13}, iter[4928], train loss: 67.774579, valid precision: 0.831800, valid loss: 64.753172\n",
    "epoch{14}, iter[5280], train loss: 65.871997, valid precision: 0.831000, valid loss: 67.388650\n",
    "epoch{15}, iter[5632], train loss: 64.865948, valid precision: 0.833200, valid loss: 66.045895\n",
    "epoch{16}, iter[5984], train loss: 63.734801, valid precision: 0.835800, valid loss: 65.672584\n",
    "epoch{17}, iter[6336], train loss: 62.797431, valid precision: 0.837200, valid loss: 65.251506\n",
    "epoch{18}, iter[6688], train loss: 61.362402, valid precision: 0.837800, valid loss: 65.890767\n",
    "epoch{19}, iter[7040], train loss: 60.573223, valid precision: 0.845000, valid loss: 64.175304\n",
    "epoch{20}, iter[7392], train loss: 59.165992, valid precision: 0.847200, valid loss: 63.679088\n",
    "epoch{21}, iter[7744], train loss: 58.805940, valid precision: 0.841200, valid loss: 64.903402\n",
    "epoch{22}, iter[8096], train loss: 57.990511, valid precision: 0.847600, valid loss: 64.460716\n",
    "epoch{23}, iter[8448], train loss: 57.435585, valid precision: 0.845600, valid loss: 64.224755\n",
    "epoch{24}, iter[8800], train loss: 56.299389, valid precision: 0.849800, valid loss: 62.474651\n",
    "epoch{25}, iter[9152], train loss: 55.588289, valid precision: 0.850800, valid loss: 64.953446"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "\n",
    "def load_log(path):\n",
    "\twith open(path, 'r') as fo:\n",
    "\t\tloss_list, train_precision_list, valid_precision_list = [], [], []\n",
    "\t\tfor line in fo:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\tpattern = re.compile(r'epoch\\{([\\d]+)\\}, iter\\[([\\d]+)\\], train loss: ([\\d\\.]+), valid precision: ([\\d\\.]+)')\n",
    "\t\t\tres = pattern.findall(line)\n",
    "\t\t\tif res:\n",
    "\t\t\t\tloss_list.append(float(res[0][2]))\n",
    "\t\t\t\tvalid_precision_list.append(float(res[0][3]))\n",
    "\treturn loss_list, valid_precision_list\n",
    "\n",
    "def curve_smooth(data_list, batch_size=100):\n",
    "\tnew_data_list, idx_list = [], []\n",
    "\tfor i in range(int(len(data_list) / batch_size)):\n",
    "\t\tbatch = data_list[i*batch_size: (i+1)*batch_size]\n",
    "\t\tnew_data_list.append(1.0 * sum(batch) / len(batch))\n",
    "\t\tidx_list.append(i*batch_size)\n",
    "\n",
    "\treturn new_data_list, idx_list\n",
    "\n",
    "def plot_curve(loss_list1, loss_idxs1, valid_precision_list1, valid_precision_idxs1,\n",
    "\tloss_list2, loss_idxs2, valid_precision_list2, valid_precision_idxs2,\n",
    "\tloss_list3, loss_idxs3, valid_precision_list3, valid_precision_idxs3,\n",
    "\tloss_list4, loss_idxs4, valid_precision_list4, valid_precision_idxs4):\n",
    "\tfig = plt.figure(figsize=(10, 5))\n",
    "\t\n",
    "\tplt.subplot(121)\n",
    "\tp1 = plt.plot(loss_idxs1, loss_list1, '.--', color='#6495ED')\n",
    "\tp2 = plt.plot(loss_idxs2, loss_list2, '.--', color='#FF6347')\n",
    "\tp3 = plt.plot(loss_idxs3, loss_list3, '.--', color='#4EEE94')\n",
    "\tp4 = plt.plot(loss_idxs4, loss_list4, '.--', color='#EEC900')\n",
    "\tplt.legend((p1[0], p2[0], p3[0], p4[0]), ('20 layers', '32 layers', '44 layers', '56 layers'))\n",
    "\tplt.grid(True)\n",
    "\tplt.title('cifar10 image classification loss')\n",
    "\tplt.xlabel('# of epoch')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.axis([0, 500, 0, 50])\n",
    "\t\"\"\"\n",
    "\tplt.subplot(132)\n",
    "\tp4 = plt.plot(train_precision_idxs1, train_precision_list1, '.--', color='#66CDAA')\n",
    "\tp5 = plt.plot(train_precision_idxs2, train_precision_list2, '.--', color='#FF6347')\n",
    "\tp6 = plt.plot(train_precision_idxs3, train_precision_list3, '.--', color='#4EEE94')\n",
    "\tplt.legend((p4[0], p5[0], p6[0]), ('only flip', 'only crop', 'only whiten'))\n",
    "\tplt.grid(True)\n",
    "\tplt.title('cifar10 image classification train precision')\n",
    "\tplt.xlabel('# of epoch')\n",
    "\tplt.ylabel('accuracy')\n",
    "\t\"\"\"\n",
    "\tplt.subplot(122)\n",
    "\tp1 = plt.plot(valid_precision_idxs1, valid_precision_list1, '.--', color='#6495ED')\n",
    "\tp2 = plt.plot(valid_precision_idxs2, valid_precision_list2, '.--', color='#FF6347')\n",
    "\tp3 = plt.plot(valid_precision_idxs3, valid_precision_list3, '.--', color='#4EEE94')\n",
    "\tp4 = plt.plot(valid_precision_idxs4, valid_precision_list4, '.--', color='#EEC900')\n",
    "\tplt.legend((p1[0], p2[0], p3[0], p4[0]), ('20 layers', '32 layers', '44 layers', '56 layers'))\n",
    "\t# plt.legend((p1[0]), ('lr = 0.01'))\n",
    "\tplt.grid(True)\n",
    "\tplt.title('cifar10 image classification valid precision')\n",
    "\tplt.xlabel('# of epoch')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.axis([0, 500, 0.8, 0.95])\n",
    "\n",
    "\t# plt.show()\n",
    "\tplt.savefig('E:\\\\Github\\cifar10-tensorflow\\\\exps\\cifar10-v20\\cifar10-v20.png', dpi=72, format='png')\n",
    "\n",
    "\n",
    "loss_list1, valid_precision_list1 = load_log('E:\\\\Github\\cifar10-tensorflow\\\\exps\\cifar10-v20\\cifar10-v20.txt')\n",
    "loss_list2, valid_precision_list2 = load_log('E:\\\\Github\\cifar10-tensorflow\\\\exps\\cifar10-v20\\cifar10-v21.txt')\n",
    "loss_list3, valid_precision_list3 = load_log('E:\\\\Github\\cifar10-tensorflow\\\\exps\\cifar10-v20\\cifar10-v22.txt')\n",
    "loss_list4, valid_precision_list4 = load_log('E:\\\\Github\\cifar10-tensorflow\\\\exps\\cifar10-v20\\cifar10-v23.txt')\n",
    "\n",
    "# print(numpy.array(loss_list[-100:]).mean(), numpy.array(train_precision_list[-100:]).mean())\n",
    "loss_list1, loss_idxs1 = curve_smooth(loss_list1, batch_size=1)\n",
    "valid_precision_list1, valid_precision_idxs1 = curve_smooth(valid_precision_list1, batch_size=1)\n",
    "loss_list2, loss_idxs2 = curve_smooth(loss_list2, batch_size=1)\n",
    "valid_precision_list2, valid_precision_idxs2 = curve_smooth(valid_precision_list2, batch_size=1)\n",
    "loss_list3, loss_idxs3 = curve_smooth(loss_list3, batch_size=1)\n",
    "valid_precision_list3, valid_precision_idxs3 = curve_smooth(valid_precision_list3, batch_size=1)\n",
    "loss_list4, loss_idxs4 = curve_smooth(loss_list4, batch_size=1)\n",
    "valid_precision_list4, valid_precision_idxs4 = curve_smooth(valid_precision_list4, batch_size=1)\n",
    "\n",
    "plot_curve(loss_list1, loss_idxs1, valid_precision_list1, valid_precision_idxs1,\n",
    "\tloss_list2, loss_idxs2, valid_precision_list2, valid_precision_idxs2,\n",
    "\tloss_list3, loss_idxs3, valid_precision_list3, valid_precision_idxs3,\n",
    "\tloss_list4, loss_idxs4, valid_precision_list4, valid_precision_idxs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
